{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de números através de imagens\n",
    "O algorimo tem como objetivo desenvolver um modelo que consiga através de imagens contendo números escrito a mão, classificar qual o número. Para isso foi usado o dataset MNIST, que é encontrado nos datasets da lib Keras. A base de dados contém 60000 imagens de escrita a mão dos números de 0 a 9. \n",
    "\n",
    "Para a resolução do problema foi escolhido o uso de __Redes Neurais Artificiais__, ao final do processo será possível fornecer imagens ao modelo e o mesmo classificará qual dígito de 0 a 9 a imagem contém."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Bibliotecas usadas\n",
    "\n",
    "Foram usadas bibliotecas padrões para manipulação de dados como __numpy__, para o desenvolvimento do modelo e algumas ferramentas extras relacionadas foi usado o __keras e sklearn__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Funções utilitárias\n",
    "\n",
    "Foram definidas algumas funções básicas para ajudar no desenvolvimento.\n",
    "\n",
    "__describe_image__: Exibe a imagem em formato grayscale.<br>\n",
    "__transform_image__: Transforma uma imagem no formato de matrix para um vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "\n",
    "def transform_image_array_to_model(images_array):\n",
    "    transformed_data = images_array.copy()\n",
    "    transformed_data = transformed_data.reshape(len(transformed_data), np.prod(transformed_data.shape[1:]))\n",
    "    transformed_data = transformed_data / 255\n",
    "    return transformed_data.astype('float32')\n",
    "\n",
    "def transform_image_class_to_model(images_class):\n",
    "    transformed_target = images_class.copy()\n",
    "    transformed_target = pd.get_dummies(transformed_target)\n",
    "    return transformed_target.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Carregamento dos dados\n",
    "\n",
    "O acesso ao dataset acontece através da lib do __keras__, onde conseguimos importar no módulo de datasets a base MNIST. Ao carregar os dados já é possível obter a divisão entre dados de treino e de teste, além de já estarem normalizados para o uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, training_target), (test_data, test_target) = mnist.load_data()\n",
    "\n",
    "print(training_data.shape, test_data.shape, training_target.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Visualizando e ententendo as imagens\n",
    "\n",
    "Percebe-se que os dados relativos a cada imagem são matrizes no formato __28 por 28__, contendo um valor na escala gray. Só a nível de curiosidade, vamos visualizar um item dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_image(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Transformação das imagens\n",
    "\n",
    "Será gerado nesse passo os previsores e as classes que serão usados para o treino e teste do modelo. O previsores (imagens) que a princípio são __matrizes 28x28__, serão transformados em um array de __784 posições__... já as classes, são valores numéricos de __0-9__, informando qual o tipo de número presente naquela imagem, essas classes serão transformadas em one hot encoder, gerando 10 colunas para cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_training_data = transform_image_array_to_model(training_data)\n",
    "transformed_test_data = transform_image_array_to_model(test_data)\n",
    "\n",
    "transformed_training_target = transform_image_class_to_model(training_target)\n",
    "transformed_test_target = transform_image_class_to_model(test_target)\n",
    "\n",
    "print(transformed_training_data.shape, transformed_test_data.shape, transformed_training_target.shape, transformed_test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Criação do modelo\n",
    "\n",
    "Criou-se o modelo, definido em 4 camadas incluindo a camada de saída, a camada de entrada contém 784 perceptrons, pois cada imagem foi mapeada em um array de 784 colunas. Adicionamos dropout para evitar o overfitting, e usou-se a função de loss do tipo __categorical_crossentropy__.\n",
    "\n",
    "A camada de saída apresenta 10 perceptrons devido a saída ser 10 classes, indo de 0 até 9, e as classes foram mapeadas em one hot encoder, gerando assim 10 colunas de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Variáveis e treinamento\n",
    "\n",
    "Definimos que o modelo iria realizar __100 epochs__, visto que rapidamente já conseguimos atingir uma boa precisão. Adicionamos também um _check pointer_ para salvar o melhor modelo entre os 100 ciclos. Em seguida, o modelo será treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/image_classification.hdf5', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(transformed_training_data, transformed_training_target, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(transformed_test_data, transformed_test_target),\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Teste de precisão\n",
    "\n",
    "Ao fim do treinamento, rodamos o modelo com os dados separados de teste para fazer uma avaliação da sua performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(transformed_test_data, transformed_test_target, verbose = 0)\n",
    "print('Precisão do modelo é de ' + str(accuracy[1]*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Teste manual\n",
    "\n",
    "Na pasta __images_extras__ foi adicionado alguns exemplos de imagens feitos por mim, para testar a eficiência do modelo. Você também pode tentar, basta fazer uma imagem com fundo preto o número na cor branca, lembrando que a imagem deve ser no formato __28x28__. Vale salientar que o modelo foi treinado com dados limpos e padronizados do dataset MNIST, então caso você coloque uma imagem muito diferente do padrão que o modelo foi treinado, possivelmente ele não será eficiente, nesse algoritmo estamos partindo do pressuposto que os dados já estão padronizados e tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_images(path):\n",
    "    image_files = glob(path)\n",
    "    images_processed = np.array([color.rgb2gray(io.imread(image)) for image in image_files])\n",
    "    return image_files, images_processed\n",
    "\n",
    "image_files, images_processed = load_png_images('images_extras/*.png')\n",
    "transformed_images_to_model = transform_image_array_to_model(images_processed * 255)\n",
    "\n",
    "manual_test_result = model.predict(transformed_images_to_model)\n",
    "manual_test_result = np.where(manual_test_result > 0.5, 1, 0)\n",
    "\n",
    "for image_index in range(0, len(images_processed)):\n",
    "    print('A imagem \"' + str(image_files[image_index]) + '\" foi classificado como o número ' + str(np.argmax(manual_test_result[image_index])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
